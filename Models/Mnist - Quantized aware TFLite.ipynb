{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28","authorship_tag":"ABX9TyOoKSInR8HCR2nX1HWWMCUe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers"],"metadata":{"id":"H7Rn9XV0zbpb","executionInfo":{"status":"ok","timestamp":1725953127166,"user_tz":-330,"elapsed":15017,"user":{"displayName":"Sanjay Kumar Kashyap","userId":"03437485894954307419"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install -q tensorflow-model-optimization"],"metadata":{"id":"fkXrvEWy014Z","executionInfo":{"status":"ok","timestamp":1725953178621,"user_tz":-330,"elapsed":3870,"user":{"displayName":"Sanjay Kumar Kashyap","userId":"03437485894954307419"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"f7SRh_5Vy3rL","executionInfo":{"status":"ok","timestamp":1725953183054,"user_tz":-330,"elapsed":1566,"user":{"displayName":"Sanjay Kumar Kashyap","userId":"03437485894954307419"}}},"outputs":[],"source":["#load MNIST dataset\n","mnist = keras.datasets.mnist\n","(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n","\n","# Normalize the input image\n","train_images = train_images/255.0\n","test_images = test_images/255.0\n","\n","# # Define the model architecture\n","# model = keras.Sequential([\n","#     keras.layers.InputLayer(input_shape = (28,28)),\n","#     keras.layers.Reshape(target_shape = (28,28,1)),\n","#     keras.layers.Conv2D(filters = 12, kernel_size = (3,3), activation = 'relu'),\n","#     keras.layers.MaxPooling2D(pool_size = (2,2)),\n","#     keras.layers.Flatten(),\n","#     keras.layers.Dense(10)\n","# ])\n","\n","# Define the model architecture\n","model = keras.Sequential([\n","    keras.layers.InputLayer(input_shape=(28, 28, 1)),  # Include channel dimension directly\n","    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n","    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(10)\n","])"]},{"cell_type":"markdown","source":["# **Optimize For Quantization**"],"metadata":{"id":"XTALd1DL1irf"}},{"cell_type":"code","source":["import tensorflow_model_optimization as tfmot"],"metadata":{"collapsed":true,"id":"FbbGA6QR1oNi","executionInfo":{"status":"ok","timestamp":1725953189122,"user_tz":-330,"elapsed":2215,"user":{"displayName":"Sanjay Kumar Kashyap","userId":"03437485894954307419"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["*The error you're encountering occurs because the Reshape layer is not supported directly by the quantization-aware training API in TensorFlow. To fix this issue, you need to use quantize_scope to handle custom layers or unsupported layers.*"],"metadata":{"id":"VYvRsaea4a1B"}},{"cell_type":"code","source":["# Use quantize_scope to handle the Reshape layer\n","with tfmot.quantization.keras.quantize_scope():\n","    # model training quantization can be done by quantize model API\n","    quantize_model = tfmot.quantization.keras.quantize_model\n","\n","    # Simply pass model & it will return a new model\n","    q_aware_model = quantize_model(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"collapsed":true,"id":"hKNsNuBH3CZA","executionInfo":{"status":"error","timestamp":1725953196422,"user_tz":-330,"elapsed":433,"user":{"displayName":"Sanjay Kumar Kashyap","userId":"03437485894954307419"}},"outputId":"43ca1a16-275e-45ee-934e-36146f4ac63b"},"execution_count":8,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"`to_quantize` can only either be a keras Sequential or Functional model.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-8393871a88ff>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Simply pass model & it will return a new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mq_aware_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36mquantize_model\u001b[0;34m(to_quantize, quantized_layer_name_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m       \u001b[0;32mand\u001b[0m \u001b[0mto_quantize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m   ):  # pylint: disable=protected-access\n\u001b[0;32m--> 135\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;34m'`to_quantize` can only either be a keras Sequential or '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;34m'Functional model.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: `to_quantize` can only either be a keras Sequential or Functional model."]}]},{"cell_type":"code","source":["# model training quantization can be done by quantize model API\n","quantize_model = tfmot.quantization.keras.quantize_model\n","\n","# simply pass model & it will return new model\n","q_aware_model = quantize_model(model)\n","\n","# recompile new model\n","q_aware_model.compile(optimizer = 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits= True), metrics = ['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":612},"collapsed":true,"id":"rOnX9ZnQ4i7Y","executionInfo":{"status":"error","timestamp":1725903954401,"user_tz":-330,"elapsed":462,"user":{"displayName":"Sanjay Kumar Kashyap","userId":"03437485894954307419"}},"outputId":"1b17df36-3574-4dac-e2a0-a4b44a0d992f"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Unable to clone model. This generally happens if you used custom Keras layers or objects in your model. Please specify them via `quantize_scope` for your calls to `quantize_model` and `quantize_apply`. [Layer <tf_keras.src.layers.convolutional.conv2d.Conv2D object at 0x788cc2925f30> supplied to wrapper is not a supported layer type. Please ensure wrapped layer is a valid Keras layer.].","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/base_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36mquantize_apply\u001b[0;34m(model, scheme, quantized_layer_name_prefix)\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m     \u001b[0mmodel_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_clone_model_with_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36m_clone_model_with_weights\u001b[0;34m(model_to_clone)\u001b[0m\n\u001b[1;32m    368\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_clone_model_with_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_clone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0mcloned_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_clone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m     \u001b[0mcloned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_clone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/cloning.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             return _clone_sequential_model(\n\u001b[0m\u001b[1;32m    528\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/cloning.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mlayer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/cloning.py\u001b[0m in \u001b[0;36m_clone_layer\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_clone_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize_annotate.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantize_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantize_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize_annotate.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer, quantize_config, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \"\"\"\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQuantizeAnnotate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/base_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0;34mf\"Layer {layer} supplied to wrapper is\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Layer <tf_keras.src.layers.convolutional.conv2d.Conv2D object at 0x788cc2925f30> supplied to wrapper is not a supported layer type. Please ensure wrapped layer is a valid Keras layer.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-a9edbcd10f3f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# simply pass model & it will return new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mq_aware_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# recompile new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36mquantize_model\u001b[0;34m(to_quantize, quantized_layer_name_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0mannotated_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize_annotate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_quantize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m   return quantize_apply(\n\u001b[0m\u001b[1;32m    142\u001b[0m       annotated_model, quantized_layer_name_prefix=quantized_layer_name_prefix)\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/keras/metrics.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMonitorBoolGauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FAILURE_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_gauge\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/keras/metrics.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMonitorBoolGauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUCCESS_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36mquantize_apply\u001b[0;34m(model, scheme, quantized_layer_name_prefix)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0mmodel_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_clone_model_with_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0;34m'Unable to clone model. This generally happens if you used custom '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;34m'Keras layers or objects in your model. Please specify them via '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unable to clone model. This generally happens if you used custom Keras layers or objects in your model. Please specify them via `quantize_scope` for your calls to `quantize_model` and `quantize_apply`. [Layer <tf_keras.src.layers.convolutional.conv2d.Conv2D object at 0x788cc2925f30> supplied to wrapper is not a supported layer type. Please ensure wrapped layer is a valid Keras layer.]."]}]},{"cell_type":"markdown","source":["# **Quantization aware Training**"],"metadata":{"id":"SUXwsRmY5Y4S"}},{"cell_type":"code","source":[],"metadata":{"id":"ECQtzEKd5I5J","executionInfo":{"status":"ok","timestamp":1725953156083,"user_tz":-330,"elapsed":5496,"user":{"displayName":"Sanjay Kumar Kashyap","userId":"03437485894954307419"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1ff92572-014e-44ee-b10e-ae2ceedc11f1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/242.5 kB\u001b[0m \u001b[31m964.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/242.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/242.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["# **Finetune baseline model to become quantize aware **"],"metadata":{"id":"vL6jYfIk8S4q"}},{"cell_type":"code","source":["import tempfile # to create temperory files and directories\n","import os # to perform OS related tasks\n","\n","\n","#load ,nist dataset\n","\n","mnist = keras.datasets.mnist\n","(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n","\n","#Mormalize\n","train_images = train_images/255.0\n","test_images = test_images/255.0\n","\n","#define Model Architecture\n","model = keras.Sequential([keras.layers.InputLayer(input_shape = (28,28)),\n","                         keras.layers.Reshape(target_shape(28,28,1)),\n","                         keras.layers.Conv2D(filter = 12, kernal_size =(3,3), activation = 'relu'),\n","                         keras.layers.MaxPooling2D(pool_size = (2,2)),\n","                         keras.layers.Flatten(),\n","                         keras.layers.Dense(10)\n","                         ])\n","model.compile(optimizer = 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), metrics = ['accuracy'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"Dy-U5YNe5vhj","executionInfo":{"status":"error","timestamp":1725905724652,"user_tz":-330,"elapsed":983,"user":{"displayName":"Sanjay Kumar Kashyap","userId":"03437485894954307419"}},"outputId":"22234708-ec29-43a4-e358-fe53cae6bba0"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'target_shape' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-92add42f4881>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#define Model Architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m model = keras.Sequential([keras.layers.InputLayer(input_shape = (28,28)),\n\u001b[0;32m---> 16\u001b[0;31m                          \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                          \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernal_size\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                          \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'target_shape' is not defined"]}]},{"cell_type":"markdown","source":["Train baseline model"],"metadata":{"id":"XTvLGCvG8q4K"}},{"cell_type":"code","source":["#instead of using train data as validation data , use 10% of training data as validation data\n","model.fit(train_images, train_labels, epochs = 1, validation_split = 0.1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":318},"id":"fZBQiKh_8vBc","executionInfo":{"status":"error","timestamp":1725905762387,"user_tz":-330,"elapsed":446,"user":{"displayName":"Sanjay Kumar Kashyap","userId":"03437485894954307419"}},"outputId":"ea0cd94a-a62c-411e-ed08-2d2cc8a48b72"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-a734aaf708ed>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#instead of using train data as validation data , use 10% of training data as validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3981\u001b[0m         \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3982\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3983\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   3984\u001b[0m                 \u001b[0;34m\"You must compile your model before \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3985\u001b[0m                 \u001b[0;34m\"training/testing. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."]}]},{"cell_type":"markdown","source":["Fine tune baseline model with Quantization aware training"],"metadata":{"id":"h-BCrdFr9Nu0"}},{"cell_type":"code","source":["# what quantization aware traininig does is it basically mimic the inference pipeline &\n","# estimate the possible errors that could arise due to converion to TF Lite model & also post training quantization"],"metadata":{"id":"Y12f-ugu9W2k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tenserflow_model_optimization as tfmot\n","\n","#instintiate api\n","auantize_model = tfmot.quantization.keras.quantize_model\n","\n","#create quantization awawre model\n","q_aware_model = quantize_model(model)\n","\n","# recompile model\n","q_aware_model.compile(optimizer = 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), metrics = ['accuracy'])\n","\n","#Traini fine tuned model\n","train_images_subset = train_images[0:1000] #out of 60000\n","train_labels_subset = train_labels[0:1000]\n","\n","#train quantization aware model\n","q_aware_model.fit(train_images_subset, train_labels_subset , batch_size = 500, epochs = 1, validation_split = 0.1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":401},"collapsed":true,"id":"FGpxJ1zJ-DK-","executionInfo":{"status":"error","timestamp":1725905775168,"user_tz":-330,"elapsed":466,"user":{"displayName":"Sanjay Kumar Kashyap","userId":"03437485894954307419"}},"outputId":"b2ddf591-f9de-4bba-ce72-5596c4779ba6"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'tenserflow_model_optimization'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-3bc11fdd180a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtenserflow_model_optimization\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfmot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#instintiate api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mauantize_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfmot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tenserflow_model_optimization'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["Evaluate both models on test dataset\n"],"metadata":{"id":"fWNOqUrRAGMr"}},{"cell_type":"code","source":["_,baseline_model_accuracy = model.evaluate(test_images, test_labels, verbose = 0)\n","_,quantize_aware_model_accuracy = q_aware_model.evaluate(test_images, test_labels, verbose = 0)\n","\n","print( \" Baseline test accuracy : \", baseline_model_accuracy)\n","print(\"Quanti aware  test accuracy : \", q_aware_model_accuracy)\n"],"metadata":{"id":"m28FG235_rzk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Now we have Quantized aware tenserflow model, now we gonna convert them into TF Lite model"],"metadata":{"id":"DQNofCmJBGpK"}},{"cell_type":"markdown","source":["create Quantized model for TFLite backend"],"metadata":{"id":"C8jqJY6GBcTS"}},{"cell_type":"code","source":["#instentiate converter\n","converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","\n","#convert the model\n","quantized_QA_tflite_model = converter.convert()"],"metadata":{"id":"T3IJxo8RBblv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Observe persistence of accuracy from TF to TF Lite"],"metadata":{"id":"7BT8sZ6zCSPK"}},{"cell_type":"code","source":["import numpy as np\n","def evaluate_model(interpreter):\n","  input_index = interpreter.get_input_details()[0][\"index\"]\n","  output_index = interpreter.get_output_details()[0][\"index\"]\n","\n","  #run predictions on every image of test dataset\n","  prediction_digits = []\n","  for i, test_image in enumerate ( test_images):\n","    if i%1000 == 0:\n","      print(\"Evaluted on {n} results \".format(n=i))\n","      #preprocessing : add batch dimension & convert to floats to match with model input format\n","      test_image = np.expand_dims(test_image, axis = 0).astype(np.float32)\n","      interpreter.set_tensor(input_index, test_image)\n","      #run inference\n","      interpreter.invoke()\n","      #post processing: remove batch dimension & find digit with highest probability\n","      output = interpreter.tensor(output_index)\n","      digit = np.argmax(output()[0])\n","      prediction_digits.append(digit)\n","  print(\"\\n\")\n","\n","  #compare prediction results with ground truth to calculate accuracy\n","  prediction_digits = np.array(prediction_digits)\n","  accuracy = (prediction_digits == test_labels).mean()\n","  return accuracy\n","\n"],"metadata":{"id":"QtNwauwhBGSf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#instintiate interpreter\n","interpreter = tf.lite.Interpreter(model_content = quantized_QA_tflite_model)\n","interpreter.allocate_tensors()\n","TFLite_quant_QA_accuracy = evaluate_model(interpreter)\n","\n","print(\" Quant Tenserflow test accuracy: \", q_aware_model_accuracy)\n","print(\"Quant TFLite test accuracy: \", TFLite_quant_QA_accuracy)"],"metadata":{"id":"m9WY_pBFFxHL"},"execution_count":null,"outputs":[]}]}