{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28","authorship_tag":"ABX9TyMvakbsMx+hSubDYYAXx9e4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ts-TL_DpQRRV","executionInfo":{"status":"ok","timestamp":1726346540715,"user_tz":-330,"elapsed":60017,"user":{"displayName":"Sanjay Kumar Kashyap","userId":"03437485894954307419"}},"outputId":"6f56354b-7d05-4afc-afee-1abea909a51e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","Epoch 1/10\n","1865/1875 [============================>.] - ETA: 0s - loss: 0.2520 - accuracy: 0.9287\n","Weights comparison after epoch 1:\n","Layer 0:\n","  Sub-layer 0 - Unchanged Weights: 10532/100352\n","  Sub-layer 1 - Unchanged Weights: 0/128\n","Layer 1:\n","  Sub-layer 0 - Unchanged Weights: 0/1280\n","  Sub-layer 1 - Unchanged Weights: 0/10\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.2517 - accuracy: 0.9288\n","Epoch 2/10\n","1869/1875 [============================>.] - ETA: 0s - loss: 0.1100 - accuracy: 0.9675\n","Weights comparison after epoch 2:\n","Layer 0:\n","  Sub-layer 0 - Unchanged Weights: 11568/100352\n","  Sub-layer 1 - Unchanged Weights: 0/128\n","Layer 1:\n","  Sub-layer 0 - Unchanged Weights: 0/1280\n","  Sub-layer 1 - Unchanged Weights: 0/10\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.1101 - accuracy: 0.9675\n","Epoch 3/10\n","1868/1875 [============================>.] - ETA: 0s - loss: 0.0747 - accuracy: 0.9772\n","Weights comparison after epoch 3:\n","Layer 0:\n","  Sub-layer 0 - Unchanged Weights: 11764/100352\n","  Sub-layer 1 - Unchanged Weights: 0/128\n","Layer 1:\n","  Sub-layer 0 - Unchanged Weights: 0/1280\n","  Sub-layer 1 - Unchanged Weights: 0/10\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0746 - accuracy: 0.9772\n","Epoch 4/10\n","1854/1875 [============================>.] - ETA: 0s - loss: 0.0557 - accuracy: 0.9833\n","Weights comparison after epoch 4:\n","Layer 0:\n","  Sub-layer 0 - Unchanged Weights: 11985/100352\n","  Sub-layer 1 - Unchanged Weights: 0/128\n","Layer 1:\n","  Sub-layer 0 - Unchanged Weights: 0/1280\n","  Sub-layer 1 - Unchanged Weights: 0/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.0556 - accuracy: 0.9833\n","Epoch 5/10\n","1865/1875 [============================>.] - ETA: 0s - loss: 0.0430 - accuracy: 0.9865\n","Weights comparison after epoch 5:\n","Layer 0:\n","  Sub-layer 0 - Unchanged Weights: 12161/100352\n","  Sub-layer 1 - Unchanged Weights: 0/128\n","Layer 1:\n","  Sub-layer 0 - Unchanged Weights: 0/1280\n","  Sub-layer 1 - Unchanged Weights: 0/10\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.0430 - accuracy: 0.9865\n","Epoch 6/10\n","1863/1875 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9894\n","Weights comparison after epoch 6:\n","Layer 0:\n","  Sub-layer 0 - Unchanged Weights: 12180/100352\n","  Sub-layer 1 - Unchanged Weights: 0/128\n","Layer 1:\n","  Sub-layer 0 - Unchanged Weights: 0/1280\n","  Sub-layer 1 - Unchanged Weights: 0/10\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0340 - accuracy: 0.9894\n","Epoch 7/10\n","1866/1875 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9912\n","Weights comparison after epoch 7:\n","Layer 0:\n","  Sub-layer 0 - Unchanged Weights: 12448/100352\n","  Sub-layer 1 - Unchanged Weights: 0/128\n","Layer 1:\n","  Sub-layer 0 - Unchanged Weights: 0/1280\n","  Sub-layer 1 - Unchanged Weights: 0/10\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0280 - accuracy: 0.9912\n","Epoch 8/10\n","1874/1875 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9931\n","Weights comparison after epoch 8:\n","Layer 0:\n","  Sub-layer 0 - Unchanged Weights: 12484/100352\n","  Sub-layer 1 - Unchanged Weights: 0/128\n","Layer 1:\n","  Sub-layer 0 - Unchanged Weights: 0/1280\n","  Sub-layer 1 - Unchanged Weights: 0/10\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0225 - accuracy: 0.9931\n","Epoch 9/10\n","1856/1875 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9946\n","Weights comparison after epoch 9:\n","Layer 0:\n","  Sub-layer 0 - Unchanged Weights: 12712/100352\n","  Sub-layer 1 - Unchanged Weights: 0/128\n","Layer 1:\n","  Sub-layer 0 - Unchanged Weights: 0/1280\n","  Sub-layer 1 - Unchanged Weights: 0/10\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0178 - accuracy: 0.9945\n","Epoch 10/10\n","1867/1875 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9952\n","Weights comparison after epoch 10:\n","Layer 0:\n","  Sub-layer 0 - Unchanged Weights: 13019/100352\n","  Sub-layer 1 - Unchanged Weights: 0/128\n","Layer 1:\n","  Sub-layer 0 - Unchanged Weights: 0/1280\n","  Sub-layer 1 - Unchanged Weights: 0/10\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0156 - accuracy: 0.9952\n","\n","Final unchanged weights mask at the end of training:\n","Layer 0:\n","  Sub-layer 0 - Unchanged Weights: 13019/100352\n","  Sub-layer 1 - Unchanged Weights: 0/128\n","Layer 1:\n","  Sub-layer 0 - Unchanged Weights: 0/1280\n","  Sub-layer 1 - Unchanged Weights: 0/10\n","313/313 [==============================] - 1s 2ms/step - loss: 0.0837 - accuracy: 0.9773\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.08371984958648682, 0.9772999882698059]"]},"metadata":{},"execution_count":1}],"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# Load and preprocess the dataset\n","data = tf.keras.datasets.mnist\n","(training_images, training_labels), (test_images, test_labels) = data.load_data()\n","\n","training_images = training_images / 255.0\n","test_images = test_images / 255.0\n","\n","# Define the model\n","model = keras.Sequential([\n","    keras.layers.Flatten(input_shape=(28,28)),\n","    keras.layers.Dense(128, activation=\"relu\"),\n","    keras.layers.Dense(10, activation=\"softmax\")\n","])\n","\n","# Compile the model\n","model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","# Custom callback to track unchanged weights\n","class WeightsTracker(tf.keras.callbacks.Callback):\n","    def on_train_begin(self, logs=None):\n","        # Save the initial weights\n","        self.previous_weights = [layer.get_weights() for layer in self.model.layers if len(layer.get_weights()) > 0]\n","        self.unchanged_weights = [[np.zeros_like(w) for w in layer_weights] for layer_weights in self.previous_weights]\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        current_weights = [layer.get_weights() for layer in self.model.layers if len(layer.get_weights()) > 0]\n","        print(f\"\\nWeights comparison after epoch {epoch + 1}:\")\n","\n","        # Compare current weights with previous weights and track unchanged weights\n","        for layer_idx, (prev_w, curr_w) in enumerate(zip(self.previous_weights, current_weights)):\n","            print(f\"Layer {layer_idx}:\")\n","            for w_idx, (prev, curr) in enumerate(zip(prev_w, curr_w)):\n","                unchanged_mask = prev == curr  # Create a mask of unchanged weights\n","                unchanged_count = np.sum(unchanged_mask)\n","                total_count = unchanged_mask.size\n","\n","                # Track unchanged weights for each sub-layer\n","                self.unchanged_weights[layer_idx][w_idx] = unchanged_mask\n","\n","                print(f\"  Sub-layer {w_idx} - Unchanged Weights: {unchanged_count}/{total_count}\")\n","\n","        # Update previous weights to current for the next epoch comparison\n","        self.previous_weights = current_weights\n","\n","    def on_train_end(self, logs=None):\n","        print(\"\\nFinal unchanged weights mask at the end of training:\")\n","        for layer_idx, weights in enumerate(self.unchanged_weights):\n","            print(f\"Layer {layer_idx}:\")\n","            for w_idx, mask in enumerate(weights):\n","                unchanged_count = np.sum(mask)\n","                total_count = mask.size\n","                print(f\"  Sub-layer {w_idx} - Unchanged Weights: {unchanged_count}/{total_count}\")\n","\n","# Instantiate the callback\n","weights_tracker = WeightsTracker()\n","\n","# Train the model with the custom callback\n","model.fit(training_images, training_labels, epochs=10, callbacks=[weights_tracker])\n","\n","# Evaluate the model\n","model.evaluate(test_images, test_labels)\n","\n","\n","\n","# input layer = 28 * 28 = 784\n","# layer 1 = Dense = 128\n","#         No. of weights from input layer to layer 1 = 784 * 128 = 1,00,352\n","#\n","# layer 2 = Dense = 10\n","#         No. of weights from layer 1 to layer 2 = 128 * 10 = 1,280\n","\n","#\n","# starting mein random initialize hua\n","# fir 1st epoch mein\n","#\n","#\n","#\n","#\n","#\n","#\n","#\n","#\n","#\n","#"]}]}